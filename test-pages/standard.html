<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta
            name="description"
            content="A standard webpage without WAIO semantic attributes"
        >
        <meta property="og:title" content="Standard Page - No WAIO">
        <meta
            property="og:description"
            content="This page demonstrates standard HTML without data-ai-* attributes"
        >
        <title>Standard Page - No WAIO Framework</title>
        <style>
            body {
                font-family: system-ui, sans-serif;
                max-width: 800px;
                margin: 0 auto;
                padding: 20px;
            }
            header {
                border-bottom: 1px solid #ccc;
                padding-bottom: 20px;
                margin-bottom: 20px;
            }
            nav {
                background: #f5f5f5;
                padding: 10px;
            }
            footer {
                margin-top: 40px;
                padding-top: 20px;
                border-top: 1px solid #ccc;
                color: #666;
            }
        </style>
    </head>
    <body>
        <header>
            <nav>
                <a href="/">Home</a> |
                <a href="/about">About</a> |
                <a href="/contact">Contact</a>
            </nav>
            <h1>Welcome to Our Standard Page</h1>
            <p class="subtitle">
                A demonstration of traditional HTML structure
            </p>
        </header>

        <main>
            <article>
                <h2>Understanding Web Content Structure</h2>
                <p>
                    This is the main content of the page. Without semantic
                    attributes, AI bots must analyze text density, tag
                    hierarchy, and class names to determine what&apos;s
                    important.
                </p>

                <p>The extraction process involves complex heuristics:</p>
                <ul>
                    <li>Calculating text-to-HTML ratio</li>
                    <li>Identifying navigation and footer elements</li>
                    <li>Scoring paragraphs based on word count</li>
                    <li>Filtering boilerplate content</li>
                </ul>

                <p>
                    This approach is computationally expensive and error-prone.
                    Bots often extract navigation menus, sidebar content, or
                    footer text as part of the "main" content.
                </p>

                <h3>The Problem with Heuristics</h3>
                <p>
                    Every website has a different structure. What works for news
                    sites may fail on e-commerce pages. AI crawlers must
                    maintain complex rulesets and constantly adapt to new
                    patterns.
                </p>
            </article>

            <aside class="sidebar">
                <h3>Related Links</h3>
                <p>
                    This sidebar content might be incorrectly classified as main
                    content by some extraction algorithms.
                </p>
            </aside>
        </main>

        <footer>
            <p>
                &copy; 2024 Demo Site. This footer should not be extracted as
                main content.
            </p>
            <p>Terms | Privacy | Cookies</p>
        </footer>
    </body>
</html>
